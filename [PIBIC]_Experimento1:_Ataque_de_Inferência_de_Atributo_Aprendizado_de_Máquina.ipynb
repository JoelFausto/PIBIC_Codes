{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AzisPJgSgu1i",
        "KkREconRmlmX",
        "Dd6grGsVX0_t",
        "8qbVdMVFrAsx",
        "GGok_vIUrPqw",
        "jFJJ-oM0XHGd",
        "aDyepHsVxYyL",
        "qsuAO9HVxhtF",
        "noAgc_gjmtyn",
        "a0N5fxsMbhKe",
        "mICpw7zk41uk",
        "Ck8mIxFI5Vos",
        "VpP9p205dct8",
        "t92T9ppD6IS6",
        "v-jeoBiK6D6x",
        "ZznSupIInYZ9",
        "18HumOLGB-WU",
        "QjrnESkn7yLq",
        "7G4MNMuP7Xrl",
        "iuB_meeyGrGB",
        "Y6tJNJWU7vEQ",
        "qBFhrd2N7rrp"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoelFausto/PIBIC_Codes/blob/main/%5BPIBIC%5D_Ataque_de_Infer%C3%AAncia_de_Atributo_Aprendizado_de_M%C3%A1quina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importação das bibliotecas básicas"
      ],
      "metadata": {
        "id": "AzisPJgSgu1i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtnXhAA8dssa"
      },
      "outputs": [],
      "source": [
        "!pip install plotly --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "fIgk3GcYgzkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ataque de Inferência de Atributo - Abordagens de Aprendizado de Máquina"
      ],
      "metadata": {
        "id": "xewe944JhCPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neste código usaremos técnicas de machine learning para inferir um atributo sensível, como uma doença ou situação socioeconômica, a partir de quase-identificadores."
      ],
      "metadata": {
        "id": "WHb8ozf0hFsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Carregar base de dados de microdados anonimizados (exemplo)\n",
        "microdados = pd.read_parquet('dadosCenso2018_FiltradoPreenchido.parquet')"
      ],
      "metadata": {
        "id": "kUBef218hPCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Árvores de Decisão"
      ],
      "metadata": {
        "id": "KkREconRmlmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando bibliotecas\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report"
      ],
      "metadata": {
        "id": "3B8CZnzaOlG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Atributo sensível ['IN_FINANCIAMENTO_ESTUDANTIL']"
      ],
      "metadata": {
        "id": "Dd6grGsVX0_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quase-identificadores e o atributo sensível a ser inferido\n",
        "quase_identificadores_list = [\n",
        "    microdados[['CO_CURSO']],\n",
        "    microdados[['CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'TP_NACIONALIDADE', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'TP_NACIONALIDADE', 'CO_PAIS_ORIGEM', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'TP_NACIONALIDADE', 'CO_PAIS_ORIGEM', 'CO_IES', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']]\n",
        "]\n",
        "\n",
        "atributo_sensivel = microdados[['IN_FINANCIAMENTO_ESTUDANTIL']]"
      ],
      "metadata": {
        "id": "AB-ZJpRDhdW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar o DataFrame vazio\n",
        "resultadosArvores_1 = pd.DataFrame(columns=[\n",
        "    'Quantidade de quaseidentificadores',\n",
        "    'Quaseidentificadores',\n",
        "    'Sucesso Determinístico a Posteriori (%)',\n",
        "    'Sucesso Probabilístico a Posteriori (%)',\n",
        "    'Degradação Privacidade Determinística (%)',\n",
        "    'Degradação Privacidade Probabilística'\n",
        "])"
      ],
      "metadata": {
        "id": "xaoE1hoIRj5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop para cada lista completa de quase-identificadores\n",
        "for quase_identificadores in quase_identificadores_list:\n",
        "  # Dividir os dados em treino e teste\n",
        "  X_train, X_test, y_train, y_test = train_test_split(quase_identificadores, atributo_sensivel, test_size=0.3, random_state=42)\n",
        "\n",
        "  # Treinar o modelo de inferência (Árvore de Decisão)\n",
        "  modelo_dt = DecisionTreeClassifier()\n",
        "  modelo_dt.fit(X_train, y_train)\n",
        "\n",
        "  # Fazer inferência no conjunto de teste\n",
        "  y_pred = modelo_dt.predict(X_test)\n",
        "  y_pred_prob = modelo_dt.predict_proba(X_test)[:, 1]  # Probabilidades para AUC-ROC\n",
        "\n",
        "  # Avaliação do Modelo\n",
        "  accuracy = accuracy_score(y_test, y_pred) # Cálculo da acurácia (Sucesso a posteriori determinístico)\n",
        "  roc_auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr') # Cálculo do AUC-ROC (Sucesso a posteriori probabilístico)\n",
        "\n",
        "  # Calcular Degradação da Privacidade\n",
        "  baseline_accuracy = max(np.mean(y_test == 1), np.mean(y_test == 0))\n",
        "  degradacao_privacidade_deterministica = accuracy - baseline_accuracy\n",
        "\n",
        "  baseline_auc = 0.4728 # Base considerada pelo TED PRICE\n",
        "  if isinstance(roc_auc, np.ndarray):  # Para o caso multiclasse\n",
        "      roc_auc_mean = np.mean(roc_auc)  # Calcula a média se for um array\n",
        "  else:\n",
        "      roc_auc_mean = roc_auc\n",
        "\n",
        "  degradacao_privacidade_probabilistica = roc_auc_mean - baseline_auc\n",
        "\n",
        "  # Adicionar os resultados ao DataFrame\n",
        "  nova_linha = pd.DataFrame({\n",
        "      'Quantidade de quaseidentificadores': [len(quase_identificadores.columns)],\n",
        "      'Quaseidentificadores': [quase_identificadores.columns.tolist()],\n",
        "      'Sucesso Determinístico a Posteriori (%)': [round(accuracy * 100, 2)],\n",
        "      'Sucesso Probabilístico a Posteriori (%)': [round(roc_auc * 100, 2)],\n",
        "      'Degradação Privacidade Determinística (%)': [round(degradacao_privacidade_deterministica * 100, 2)],\n",
        "      'Degradação Privacidade Probabilística': [degradacao_privacidade_probabilistica]\n",
        "  })\n",
        "\n",
        "  resultadosArvores_1 = pd.concat([resultadosArvores_1, nova_linha], ignore_index=True)"
      ],
      "metadata": {
        "id": "scluoBa6v1b1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar formatação de porcentagem na exibição\n",
        "resultadosArvores_1 = resultadosArvores_1.style.format({\n",
        "    'Sucesso Determinístico a Posteriori (%)': '{:.2f}%',\n",
        "    'Sucesso Probabilístico a Posteriori (%)': '{:.2f}%',\n",
        "    'Degradação Privacidade Determinística (%)': '{:.2f}%',\n",
        "})\n",
        "\n",
        "# Exibir o DataFrame com formatação\n",
        "resultadosArvores_1"
      ],
      "metadata": {
        "id": "JkGHqS7oUMS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Atributo sensível ['IN_DEFICIENCIA']"
      ],
      "metadata": {
        "id": "jFJJ-oM0XHGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quase-identificadores e o atributo sensível a ser inferido\n",
        "quase_identificadores_list = [\n",
        "    microdados[['CO_CURSO']],\n",
        "    microdados[['CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'TP_NACIONALIDADE', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'TP_NACIONALIDADE', 'CO_PAIS_ORIGEM', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'TP_NACIONALIDADE', 'CO_PAIS_ORIGEM', 'CO_IES', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']]\n",
        "]\n",
        "\n",
        "atributo_sensivel = microdados[['IN_DEFICIENCIA']]"
      ],
      "metadata": {
        "id": "Com6g1mPxYyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar o DataFrame vazio\n",
        "resultadosArvores_2 = pd.DataFrame(columns=[\n",
        "    'Quantidade de quaseidentificadores',\n",
        "    'Quaseidentificadores',\n",
        "    'Sucesso Determinístico a Posteriori (%)',\n",
        "    'Sucesso Probabilístico a Posteriori (%)',\n",
        "    'Degradação Privacidade Determinística (%)',\n",
        "    'Degradação Privacidade Probabilística'\n",
        "])"
      ],
      "metadata": {
        "id": "ZNmgf0l5xYyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop para cada lista completa de quase-identificadores\n",
        "for quase_identificadores in quase_identificadores_list:\n",
        "  # Dividir os dados em treino e teste\n",
        "  X_train, X_test, y_train, y_test = train_test_split(quase_identificadores, atributo_sensivel, test_size=0.3, random_state=42)\n",
        "\n",
        "  # Treinar o modelo de inferência (Árvore de Decisão)\n",
        "  modelo_dt = DecisionTreeClassifier()\n",
        "  modelo_dt.fit(X_train, y_train)\n",
        "\n",
        "  # Fazer inferência no conjunto de teste\n",
        "  y_pred = modelo_dt.predict(X_test)\n",
        "  y_pred_prob = modelo_dt.predict_proba(X_test)  # Mantenha todas as colunas\n",
        "\n",
        "  # Avaliação do Modelo\n",
        "  accuracy = accuracy_score(y_test, y_pred) # Cálculo da acurácia (Sucesso a posteriori determinístico)\n",
        "\n",
        "  # Cálculo do AUC-ROC (Sucesso a posteriori probabilístico)\n",
        "  if len(np.unique(y_test)) == 2:  # Se for um problema binário\n",
        "      roc_auc = roc_auc_score(y_test, y_pred_prob[:, 1])  # Use apenas a coluna da classe positiva\n",
        "  else:\n",
        "      roc_auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr')  # Para múltiplas classes\n",
        "\n",
        "  # Calcular Degradação da Privacidade\n",
        "  baseline_accuracy = max(np.mean(y_test == 1), np.mean(y_test == 0))  # Maior classe\n",
        "  degradacao_privacidade_deterministica = accuracy - baseline_accuracy\n",
        "\n",
        "  baseline_auc = 0.94 # Base considerada pelo TED PRICE\n",
        "  if isinstance(roc_auc, np.ndarray):  # Para o caso multiclasse\n",
        "      roc_auc_mean = np.mean(roc_auc)  # Calcula a média se for um array\n",
        "  else:\n",
        "      roc_auc_mean = roc_auc\n",
        "\n",
        "  degradacao_privacidade_probabilistica = roc_auc_mean - baseline_auc\n",
        "\n",
        "  # Adicionar os resultados ao DataFrame\n",
        "  nova_linha = pd.DataFrame({\n",
        "      'Quantidade de quaseidentificadores': [len(quase_identificadores.columns)],\n",
        "      'Quaseidentificadores': [quase_identificadores.columns.tolist()],\n",
        "      'Sucesso Determinístico a Posteriori (%)': [round(accuracy * 100, 2)],\n",
        "      'Sucesso Probabilístico a Posteriori (%)': [round(roc_auc * 100, 2)],\n",
        "      'Degradação Privacidade Determinística (%)': [round(degradacao_privacidade_deterministica * 100, 2)],\n",
        "      'Degradação Privacidade Probabilística': [degradacao_privacidade_probabilistica]\n",
        "  })\n",
        "\n",
        "  resultadosArvores_2 = pd.concat([resultadosArvores_2, nova_linha], ignore_index=True)"
      ],
      "metadata": {
        "id": "ttsosI4BxYyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar formatação de porcentagem na exibição\n",
        "resultadosArvores_2 = resultadosArvores_2.style.format({\n",
        "    'Sucesso Determinístico a Posteriori (%)': '{:.2f}%',\n",
        "    'Sucesso Probabilístico a Posteriori (%)': '{:.2f}%',\n",
        "    'Degradação Privacidade Determinística (%)': '{:.2f}%',\n",
        "})\n",
        "\n",
        "# Exibir o DataFrame com formatação\n",
        "resultadosArvores_2"
      ],
      "metadata": {
        "id": "vbr6DqFJxYyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Forest"
      ],
      "metadata": {
        "id": "noAgc_gjmtyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando bibliotecas\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report"
      ],
      "metadata": {
        "id": "HYrpduACbWRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Atributo sensível ['IN_FINANCIAMENTO_ESTUDANTIL']"
      ],
      "metadata": {
        "id": "a0N5fxsMbhKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quase-identificadores e o atributo sensível a ser inferido\n",
        "quase_identificadores_list = [\n",
        "    microdados[['CO_CURSO']],\n",
        "    microdados[['CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'TP_NACIONALIDADE', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'TP_NACIONALIDADE', 'CO_PAIS_ORIGEM', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'TP_NACIONALIDADE', 'CO_PAIS_ORIGEM', 'CO_IES', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']]\n",
        "]\n",
        "\n",
        "atributo_sensivel = microdados[['IN_FINANCIAMENTO_ESTUDANTIL']]"
      ],
      "metadata": {
        "id": "oEv_EtjK41ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar o DataFrame vazio\n",
        "resultadosRandomForest_1 = pd.DataFrame(columns=[\n",
        "    'Quantidade de quaseidentificadores',\n",
        "    'Quaseidentificadores',\n",
        "    'Sucesso Determinístico a Posteriori (%)',\n",
        "    'Sucesso Probabilístico a Posteriori (%)',\n",
        "    'Degradação Privacidade Determinística (%)',\n",
        "    'Degradação Privacidade Probabilística'\n",
        "])"
      ],
      "metadata": {
        "id": "oqrxyeKP41um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop para cada lista completa de quase-identificadores\n",
        "for quase_identificadores in quase_identificadores_list:\n",
        "  # Dividir os dados em treino e teste\n",
        "  X_train, X_test, y_train, y_test = train_test_split(quase_identificadores, atributo_sensivel, test_size=0.3, random_state=42)\n",
        "\n",
        "  # Treinar o modelo Random Forest\n",
        "  modelo_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "  modelo_rf.fit(X_train, y_train)\n",
        "\n",
        "  # Fazer inferências no conjunto de teste\n",
        "  y_pred = modelo_rf.predict(X_test)\n",
        "  y_pred_prob = modelo_rf.predict_proba(X_test)[:, 1] # Probabilidades para AUC-ROC\n",
        "\n",
        "  # Avaliação do Modelo\n",
        "  accuracy = accuracy_score(y_test, y_pred) # Cálculo da acurácia (Sucesso a posteriori determinístico)\n",
        "  roc_auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr') # Cálculo do AUC-ROC (Sucesso a posteriori probabilístico) com suporte a múltiplas classes\n",
        "\n",
        "  # Calcular Degradação da Privacidade | Acurácia aleatória (modelo de base ingênuo)\n",
        "  baseline_accuracy = max(np.mean(y_test == 1), np.mean(y_test == 0))  # Maior classe\n",
        "  degradacao_privacidade_deterministica = accuracy - baseline_accuracy\n",
        "\n",
        "  baseline_auc = 0.4728 # Base considerada pelo TED PRICE\n",
        "  if isinstance(roc_auc, np.ndarray):  # Para o caso multiclasse\n",
        "      roc_auc_mean = np.mean(roc_auc)  # Calcula a média se for um array\n",
        "  else:\n",
        "      roc_auc_mean = roc_auc\n",
        "\n",
        "  degradacao_privacidade_probabilistica = roc_auc_mean - baseline_auc\n",
        "\n",
        "  # Adicionar os resultados ao DataFrame\n",
        "  nova_linha = pd.DataFrame({\n",
        "      'Quantidade de quaseidentificadores': [len(quase_identificadores.columns)],\n",
        "      'Quaseidentificadores': [quase_identificadores.columns.tolist()],\n",
        "      'Sucesso Determinístico a Posteriori (%)': [round(accuracy * 100, 2)],\n",
        "      'Sucesso Probabilístico a Posteriori (%)': [round(roc_auc * 100, 2)],\n",
        "      'Degradação Privacidade Determinística (%)': [round(degradacao_privacidade_deterministica * 100, 2)],\n",
        "      'Degradação Privacidade Probabilística': [degradacao_privacidade_probabilistica]\n",
        "  })\n",
        "\n",
        "  resultadosRandomForest_1 = pd.concat([resultadosRandomForest_1, nova_linha], ignore_index=True)"
      ],
      "metadata": {
        "id": "5OAcnR_E41um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar formatação de porcentagem na exibição\n",
        "resultadosRandomForest_1 = resultadosRandomForest_1.style.format({\n",
        "    'Sucesso Determinístico a Posteriori (%)': '{:.2f}%',\n",
        "    'Sucesso Probabilístico a Posteriori (%)': '{:.2f}%',\n",
        "    'Degradação Privacidade Determinística (%)': '{:.2f}%',\n",
        "})\n",
        "\n",
        "# Exibir o DataFrame com formatação\n",
        "resultadosRandomForest_1"
      ],
      "metadata": {
        "id": "cD_2xBWl41um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Atributo sensível ['IN_DEFICIENCIA']"
      ],
      "metadata": {
        "id": "VpP9p205dct8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quase-identificadores e o atributo sensível a ser inferido\n",
        "quase_identificadores_list = [\n",
        "    microdados[['CO_CURSO']],\n",
        "    microdados[['CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'TP_NACIONALIDADE', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'TP_NACIONALIDADE', 'CO_PAIS_ORIGEM', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'TP_NACIONALIDADE', 'CO_PAIS_ORIGEM', 'CO_IES', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']]\n",
        "]\n",
        "\n",
        "atributo_sensivel = microdados[['IN_DEFICIENCIA']]"
      ],
      "metadata": {
        "id": "GuPtY7um6Gpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar o DataFrame vazio\n",
        "resultadosRandomForest_2 = pd.DataFrame(columns=[\n",
        "    'Quantidade de quaseidentificadores',\n",
        "    'Quaseidentificadores',\n",
        "    'Sucesso Determinístico a Posteriori (%)',\n",
        "    'Sucesso Probabilístico a Posteriori (%)',\n",
        "    'Degradação Privacidade Determinística (%)',\n",
        "    'Degradação Privacidade Probabilística'\n",
        "])"
      ],
      "metadata": {
        "id": "nFXWInGo6UvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop para cada lista completa de quase-identificadores\n",
        "for quase_identificadores in quase_identificadores_list:\n",
        "  # Dividir os dados em treino e teste\n",
        "  X_train, X_test, y_train, y_test = train_test_split(quase_identificadores, atributo_sensivel, test_size=0.3, random_state=42)\n",
        "\n",
        "  # Treinar o modelo Random Forest\n",
        "  modelo_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "  modelo_rf.fit(X_train, y_train)\n",
        "\n",
        "  # Fazer inferência no conjunto de teste\n",
        "  y_pred = modelo_rf.predict(X_test)\n",
        "  y_pred_prob = modelo_rf.predict_proba(X_test)\n",
        "\n",
        "  # Avaliação do Modelo\n",
        "  accuracy = accuracy_score(y_test, y_pred) # Cálculo da acurácia (Sucesso a posteriori determinístico)\n",
        "\n",
        "  # Cálculo do AUC-ROC (Sucesso a posteriori probabilístico)\n",
        "  if len(np.unique(y_test)) == 2:  # Se for um problema binário\n",
        "      roc_auc = roc_auc_score(y_test, y_pred_prob[:, 1])  # Use apenas a coluna da classe positiva\n",
        "  else:\n",
        "      roc_auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr')  # Para múltiplas classes\n",
        "\n",
        "  # Calcular Degradação da Privacidade\n",
        "  baseline_accuracy = max(np.mean(y_test == 1), np.mean(y_test == 0))  # Maior classe\n",
        "  degradacao_privacidade_deterministica = accuracy - baseline_accuracy\n",
        "\n",
        "  baseline_auc = 0.94 # Base considerada pelo TED PRICE\n",
        "  if isinstance(roc_auc, np.ndarray):  # Para o caso multiclasse\n",
        "      roc_auc_mean = np.mean(roc_auc)  # Calcula a média se for um array\n",
        "  else:\n",
        "      roc_auc_mean = roc_auc\n",
        "\n",
        "  degradacao_privacidade_probabilistica = roc_auc_mean - baseline_auc\n",
        "\n",
        "  # Adicionar os resultados ao DataFrame\n",
        "  nova_linha = pd.DataFrame({\n",
        "      'Quantidade de quaseidentificadores': [len(quase_identificadores.columns)],\n",
        "      'Quaseidentificadores': [quase_identificadores.columns.tolist()],\n",
        "      'Sucesso Determinístico a Posteriori (%)': [round(accuracy * 100, 2)],\n",
        "      'Sucesso Probabilístico a Posteriori (%)': [round(roc_auc * 100, 2)],\n",
        "      'Degradação Privacidade Determinística (%)': [round(degradacao_privacidade_deterministica * 100, 2)],\n",
        "      'Degradação Privacidade Probabilística': [degradacao_privacidade_probabilistica]\n",
        "  })\n",
        "\n",
        "  resultadosRandomForest_2 = pd.concat([resultadosRandomForest_2, nova_linha], ignore_index=True)"
      ],
      "metadata": {
        "id": "Er6x6yC66Ut5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar formatação de porcentagem na exibição\n",
        "resultadosRandomForest_2 = resultadosRandomForest_2.style.format({\n",
        "    'Sucesso Determinístico a Posteriori (%)': '{:.2f}%',\n",
        "    'Sucesso Probabilístico a Posteriori (%)': '{:.2f}%',\n",
        "    'Degradação Privacidade Determinística (%)': '{:.2f}%',\n",
        "})\n",
        "\n",
        "# Exibir o DataFrame com formatação\n",
        "resultadosRandomForest_2"
      ],
      "metadata": {
        "id": "iY4zI9Jk6k_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Redes Neurais"
      ],
      "metadata": {
        "id": "ZznSupIInYZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando bibliotecas\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "from scipy.stats import entropy\n",
        "from sklearn.preprocessing import label_binarize"
      ],
      "metadata": {
        "id": "03XqP8mqBfyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Atributo sensível ['IN_FINANCIAMENTO_ESTUDANTIL']"
      ],
      "metadata": {
        "id": "18HumOLGB-WU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quase-identificadores e o atributo sensível a ser inferido\n",
        "quase_identificadores_list = [\n",
        "    microdados[['CO_CURSO']],\n",
        "    microdados[['CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'TP_NACIONALIDADE', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'TP_NACIONALIDADE', 'CO_PAIS_ORIGEM', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'TP_NACIONALIDADE', 'CO_PAIS_ORIGEM', 'CO_IES', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']]\n",
        "]\n",
        "\n",
        "atributo_sensivel = microdados[['IN_FINANCIAMENTO_ESTUDANTIL']]"
      ],
      "metadata": {
        "id": "FEl-E_kL7y_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar o DataFrame vazio\n",
        "resultadosRedesNeurais_1 = pd.DataFrame(columns=[\n",
        "    'Quantidade de quaseidentificadores',\n",
        "    'Quaseidentificadores',\n",
        "    'Sucesso Determinístico a Posteriori (%)',\n",
        "    'Sucesso Probabilístico a Posteriori (%)',\n",
        "    'Degradação Privacidade Determinística (%)',\n",
        "    'Degradação Privacidade Probabilística'\n",
        "])"
      ],
      "metadata": {
        "id": "XLMZ-Xa78rfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop para cada lista completa de quase-identificadores\n",
        "for quase_identificadores in quase_identificadores_list:\n",
        "  # Dividir os dados em treino e teste\n",
        "  X_train, X_test, y_train, y_test = train_test_split(quase_identificadores, atributo_sensivel, test_size=0.3, random_state=42)\n",
        "\n",
        "  # Normalizar os dados\n",
        "  scaler = StandardScaler()\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  # Construir a Rede Neural\n",
        "  modelo = Sequential()\n",
        "  modelo.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))  # Camada oculta com 64 neurônios\n",
        "  modelo.add(Dense(32, activation='relu'))  # Outra camada oculta com 32 neurônios\n",
        "  modelo.add(Dense(1, activation='sigmoid'))  # Saída binária\n",
        "\n",
        "  # Compilar o modelo\n",
        "  modelo.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  # Treinar a rede\n",
        "  modelo.fit(X_train, y_train, epochs=10, batch_size=10, verbose=1)\n",
        "\n",
        "  # Fazer inferências no conjunto de teste\n",
        "  y_pred_prob = modelo.predict(X_test)  # Probabilidades de classe\n",
        "  y_pred = (y_pred_prob > 0.5).astype(\"int32\")  # Converte probabilidades para classes\n",
        "\n",
        "  # Avaliação do Modelo\n",
        "  accuracy = accuracy_score(y_test, y_pred) # Cálculo da acurácia (Sucesso a posteriori determinístico)\n",
        "  # Cálculo do AUC-ROC (Sucesso a posteriori probabilístico) com suporte a múltiplas classes\n",
        "  roc_auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr')\n",
        "\n",
        "  # Calcular Degradação da Privacidade | Acurácia aleatória (modelo de base ingênuo)\n",
        "  baseline_accuracy = max(np.mean(y_test == 1), np.mean(y_test == 0))  # Maior classe\n",
        "  degradacao_privacidade_deterministica = accuracy - baseline_accuracy\n",
        "\n",
        "  baseline_auc = 0.4728 # Base considerada pelo TED PRICE\n",
        "  if isinstance(roc_auc, np.ndarray):  # Para o caso multiclasse\n",
        "      roc_auc_mean = np.mean(roc_auc)  # Calcula a média se for um array\n",
        "  else:\n",
        "      roc_auc_mean = roc_auc\n",
        "\n",
        "  degradacao_privacidade_probabilistica = roc_auc_mean - baseline_auc\n",
        "\n",
        "  # Adicionar os resultados ao DataFrame\n",
        "  nova_linha = pd.DataFrame({\n",
        "      'Quantidade de quaseidentificadores': [len(quase_identificadores.columns)],\n",
        "      'Quaseidentificadores': [quase_identificadores.columns.tolist()],\n",
        "      'Sucesso Determinístico a Posteriori (%)': [round(accuracy * 100, 2)],\n",
        "      'Sucesso Probabilístico a Posteriori (%)': [round(roc_auc_mean * 100, 2)],\n",
        "      'Degradação Privacidade Determinística (%)': [round(degradacao_privacidade_deterministica * 100, 2)],\n",
        "      'Degradação Privacidade Probabilística': [degradacao_privacidade_probabilistica]\n",
        "  })\n",
        "\n",
        "  resultadosRedesNeurais_1 = pd.concat([resultadosRedesNeurais_1, nova_linha], ignore_index=True)"
      ],
      "metadata": {
        "id": "AsvXxWRd76hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar formatação de porcentagem na exibição\n",
        "resultadosRedesNeurais_1 = resultadosRedesNeurais_1.style.format({\n",
        "    'Sucesso Determinístico a Posteriori (%)': '{:.2f}%',\n",
        "    'Sucesso Probabilístico a Posteriori (%)': '{:.2f}%',\n",
        "    'Degradação Privacidade Determinística (%)': '{:.2f}%',\n",
        "})\n",
        "\n",
        "# Exibir o DataFrame com formatação\n",
        "resultadosRedesNeurais_1"
      ],
      "metadata": {
        "id": "H-6LzHfk8yJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Atributo sensível ['IN_DEFICIENCIA']"
      ],
      "metadata": {
        "id": "iuB_meeyGrGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quase-identificadores e o atributo sensível a ser inferido\n",
        "quase_identificadores_list = [\n",
        "    microdados[['CO_CURSO']],\n",
        "    microdados[['CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'TP_NACIONALIDADE', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'TP_NACIONALIDADE', 'CO_PAIS_ORIGEM', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']],\n",
        "    microdados[['NU_DIA_NASCIMENTO', 'NU_MES_NASCIMENTO', 'NU_ANO_NASCIMENTO', 'TP_SEXO', 'TP_COR_RACA', 'CO_MUNICIPIO_NASCIMENTO', 'TP_NACIONALIDADE', 'CO_PAIS_ORIGEM', 'CO_IES', 'CO_CURSO', 'TP_ESCOLA_CONCLUSAO_ENS_MEDIO']]\n",
        "]\n",
        "\n",
        "atributo_sensivel = microdados[['IN_DEFICIENCIA']]"
      ],
      "metadata": {
        "id": "btCvclGg7unB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar o DataFrame vazio\n",
        "resultadosRedesNeurais_2 = pd.DataFrame(columns=[\n",
        "    'Quantidade de quaseidentificadores',\n",
        "    'Quaseidentificadores',\n",
        "    'Sucesso Determinístico a Posteriori (%)',\n",
        "    'Sucesso Probabilístico a Posteriori (%)',\n",
        "    'Degradação Privacidade Determinística (%)',\n",
        "    'Degradação Privacidade Probabilística'\n",
        "])"
      ],
      "metadata": {
        "id": "LjdPTD9A72vJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop para cada lista completa de quase-identificadores\n",
        "for quase_identificadores in quase_identificadores_list:\n",
        "  # Dividir os dados em treino e teste\n",
        "  X_train, X_test, y_train, y_test = train_test_split(quase_identificadores, atributo_sensivel, test_size=0.3, random_state=42)\n",
        "\n",
        "  # Normalizar os dados\n",
        "  scaler = StandardScaler()\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  # Construir a Rede Neural\n",
        "  modelo = Sequential()\n",
        "  modelo.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))  # Camada oculta com 64 neurônios\n",
        "  modelo.add(Dense(32, activation='relu'))  # Outra camada oculta com 32 neurônios\n",
        "  modelo.add(Dense(1, activation='sigmoid'))  # Saída binária\n",
        "\n",
        "  # Compilar o modelo\n",
        "  modelo.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  # Treinar a rede\n",
        "  modelo.fit(X_train, y_train, epochs=10, batch_size=10, verbose=1)\n",
        "\n",
        "  # Fazer inferências no conjunto de teste\n",
        "  y_pred_prob = modelo.predict(X_test)  # Probabilidades de classe\n",
        "  y_pred = (y_pred_prob > 0.5).astype(\"int32\")  # Converte probabilidades para classes\n",
        "\n",
        "  # Avaliação do Modelo\n",
        "  accuracy = accuracy_score(y_test, y_pred) # Cálculo da acurácia (Sucesso a posteriori determinístico)\n",
        "\n",
        "  # Cálculo do AUC-ROC (Sucesso a posteriori probabilístico)\n",
        "  # Verifique se há duas classes em y_test\n",
        "  n_classes = len(np.unique(y_test))\n",
        "  if n_classes == 2:\n",
        "      # AUC-ROC para problema binário\n",
        "      roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "  else:\n",
        "      # Binarize y_test para multi-classe e calcular o AUC-ROC\n",
        "      y_test_binarized = label_binarize(y_test, classes=np.unique(y_test))\n",
        "      roc_auc = roc_auc_score(y_test_binarized, y_pred_prob, multi_class='ovr')\n",
        "  # print(f\"AUC-ROC (Redes Neurais): {roc_auc:.2f}\")\n",
        "\n",
        "  # Calcular Degradação da Privacidade | Acurácia aleatória (modelo de base ingênuo)\n",
        "  baseline_accuracy = max(np.mean(y_test == 1), np.mean(y_test == 0))  # Maior classe\n",
        "  degradacao_privacidade_deterministica = accuracy - baseline_accuracy\n",
        "\n",
        "  baseline_auc = 0.94 # Base considerada pelo TED PRICE\n",
        "  if isinstance(roc_auc, np.ndarray):  # Para o caso multiclasse\n",
        "    roc_auc_mean = np.mean(roc_auc)  # Calcula a média se for um array\n",
        "  else:\n",
        "    roc_auc_mean = roc_auc\n",
        "\n",
        "  degradacao_privacidade_probabilistica = roc_auc - baseline_auc\n",
        "\n",
        "  # Adicionar os resultados ao DataFrame\n",
        "  nova_linha = pd.DataFrame({\n",
        "      'Quantidade de quaseidentificadores': [len(quase_identificadores.columns)],\n",
        "      'Quaseidentificadores': [quase_identificadores.columns.tolist()],\n",
        "      'Sucesso Determinístico a Posteriori (%)': [round(accuracy * 100, 2)],\n",
        "      'Sucesso Probabilístico a Posteriori (%)': [round(roc_auc_mean * 100, 2)],\n",
        "      'Degradação Privacidade Determinística (%)': [round(degradacao_privacidade_deterministica * 100, 2)],\n",
        "      'Degradação Privacidade Probabilística': [degradacao_privacidade_probabilistica]\n",
        "  })\n",
        "\n",
        "  resultadosRedesNeurais_2 = pd.concat([resultadosRedesNeurais_2, nova_linha], ignore_index=True)"
      ],
      "metadata": {
        "id": "aOL2zwDS8IYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar formatação de porcentagem na exibição\n",
        "resultadosRedesNeurais_2 = resultadosRedesNeurais_2.style.format({\n",
        "    'Sucesso Determinístico a Posteriori (%)': '{:.2f}%',\n",
        "    'Sucesso Probabilístico a Posteriori (%)': '{:.2f}%',\n",
        "    'Degradação Privacidade Determinística (%)': '{:.2f}%',\n",
        "})\n",
        "\n",
        "# Exibir o DataFrame com formatação\n",
        "resultadosRedesNeurais_2"
      ],
      "metadata": {
        "id": "alacDBqw8eB3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
